{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "- A feature extraction technique.\n",
    "- Instead of describing the data with the original features, PCA describes it with its axes of variation. \n",
    "- Axes of variation refer to the directions in which your data varies the most.\n",
    "- The axes of variation become the new features. \n",
    "- The principal components become the new features by a rotation of the dataset in the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Features (Principal Components):\n",
    "- These are linear combinations of the original features.\n",
    "- They are uncorrelated with each other (orthogonal).\n",
    "- Each new feature (component) captures a certain amount of variance in the data.\n",
    "- The first component captures the most variance, the second the next most (and so on)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why create new features?\n",
    "- Reduce dimensionality to speed up learning.\n",
    "- Remove noise or redundancy (if some features are correlated).\n",
    "- Visualize high-dimensional data in 2D/3D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Digit Dataset\n",
    "- This dataset is made up of 1797 8x8 grayscale images of hand-written digits.\n",
    "- In sklearn, each digir is stored as a feature vector of length 64.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "digits = datasets.load_digits() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n- C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n  Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n  Graduate Studies in Science and Engineering, Bogazici University.\\n- E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n- Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n  Linear dimensionalityreduction using relevance weighted LDA. School of\\n  Electrical and Electronic Engineering Nanyang Technological University.\\n  2005.\\n- Claudio Gentile. A New Approximate Maximal Margin Classification\\n  Algorithm. NIPS. 2000.\\n\\n|details-end|\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the last digit\n",
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(digits.images[-1], cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the feature matrix\n",
    "features = StandardScaler().fit_transform(digits.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA that will retain 99% of variance \n",
    "\n",
    "pca = PCA(n_components=0.99, whiten=True)  \n",
    "# n_components=0.99, keeps enough components to explain at least 95% of the variance in the dataset.\n",
    "#pca = PCA(n_components=10, whiten=True) \n",
    "# n_components=10, keeps 10 most imporatnt features\n",
    "# whiten=True scales each principal component to have unit variance. \n",
    "# This is the \"whitening\" step â€” it transforms the data to be like white noise (uncorrelated and standardized).\n",
    "\n",
    "# Conduct PCA \n",
    "features_pca = pca.fit_transform(features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 54\n"
     ]
    }
   ],
   "source": [
    "# Show results \n",
    "print(\"Original number of features:\", features.shape[1]) \n",
    "print(\"Reduced number of features:\", features_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA component shape: (54, 64)\n"
     ]
    }
   ],
   "source": [
    "print(\"PCA component shape: {}\".format(pca.components_.shape)) \n",
    "# pca.components_ is a 2D NumPy array of shape (n_components, n_features)\n",
    "# where:\n",
    "# Each row is a principal component (i.e., a direction in feature space).\n",
    "# Each column shows how much that original feature contributes to that component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components:\n",
      "[[ 1.21482737e-18 -1.82233917e-01 -2.85867997e-01 ... -1.03198001e-01\n",
      "  -1.19810604e-01 -7.14936163e-02]\n",
      " [-7.62433540e-19  4.70270076e-02  5.95647953e-02 ... -2.42617777e-01\n",
      "  -1.65089262e-01 -7.13292370e-02]\n",
      " [-3.56880226e-18  2.35882143e-02 -5.67987457e-02 ... -2.22795243e-02\n",
      "   1.00365586e-01  9.24458865e-02]\n",
      " ...\n",
      " [ 4.82989434e-18 -2.36573940e-02 -2.15711594e-02 ...  1.46857639e-02\n",
      "  -7.04598280e-02  2.03743055e-02]\n",
      " [-4.23282686e-18 -1.59521850e-01 -2.79407118e-03 ...  1.02094964e-01\n",
      "   1.00130796e-01 -9.54418079e-02]\n",
      " [ 7.46301185e-19 -2.03051327e-01 -7.68724457e-02 ... -1.10157994e-01\n",
      "   8.59937001e-02 -2.98885846e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(\"PCA components:\\n{}\".format(pca.components_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12033916, 0.09561054, 0.08444415, 0.06498408, 0.04860155,\n",
       "       0.0421412 , 0.03942083, 0.03389381, 0.02998221, 0.02932003,\n",
       "       0.02781805, 0.02577055, 0.02275303, 0.0222718 , 0.02165229,\n",
       "       0.01914167, 0.01775547, 0.01638069, 0.0159646 , 0.01489191,\n",
       "       0.0134797 , 0.01271931, 0.01165837, 0.01057647, 0.00975316,\n",
       "       0.00944559, 0.00863014, 0.00836643, 0.00797693, 0.00746471,\n",
       "       0.00725582, 0.00691911, 0.00653909, 0.00640793, 0.00591384,\n",
       "       0.00571162, 0.00523637, 0.00481808, 0.00453719, 0.00423163,\n",
       "       0.00406053, 0.00397085, 0.00356493, 0.00340787, 0.00327835,\n",
       "       0.00311032, 0.00288575, 0.00276489, 0.00259175, 0.00234483,\n",
       "       0.00218257, 0.00203598, 0.00195512, 0.00183318])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_ \n",
    "# Component 1 explains 12% variance, \n",
    "# Component 2 explains 9% variance, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Features When Data is Linearly Inseparable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries \n",
    "from sklearn.decomposition import PCA, KernelPCA \n",
    "from sklearn.datasets import make_circles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linearly inseparable data \n",
    "features, _ = make_circles(n_samples=1000, random_state=1, noise=0.1,factor=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23058395, -0.10671314],\n",
       "       [-0.0834218 , -0.22647078],\n",
       "       [ 0.9246533 , -0.71492522],\n",
       "       ...,\n",
       "       [ 0.02517206,  0.00964548],\n",
       "       [-0.92836187,  0.06693357],\n",
       "       [ 1.03502248,  0.54878286]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 2\n",
      "Reduced number of features: 1\n"
     ]
    }
   ],
   "source": [
    "# Apply kernal PCA with radius basis function (RBF) kernel \n",
    "# Kernels allow to project the linearly inseparable data into a higher dimension where it is linearly \n",
    "# separable\n",
    "kpca = KernelPCA(kernel=\"rbf\", gamma=15, n_components=1) \n",
    "features_kpca = kpca.fit_transform(features) \n",
    "print(\"Original number of features:\", features.shape[1]) \n",
    "print(\"Reduced number of features:\", features_kpca.shape[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
